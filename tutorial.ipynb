{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System Tutorial\n",
    "\n",
    "This notebook provides a detailed explanation of how our RAG (Retrieval-Augmented Generation) system works. We'll go through each component and explain its role in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to RAG\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique that combines two main components:\n",
    "\n",
    "1. **Retrieval**: Finding relevant information from a knowledge base\n",
    "2. **Generation**: Using a language model to generate answers based on the retrieved information\n",
    "\n",
    "This approach helps language models provide more accurate and up-to-date information by grounding their responses in specific documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. System Architecture\n",
    "\n",
    "Our RAG system consists of several key components:\n",
    "\n",
    "1. **Document Processor**: Handles loading and processing different types of documents\n",
    "2. **Vector Store**: Manages the storage and retrieval of document embeddings\n",
    "3. **RAG System**: Combines retrieval and generation\n",
    "4. **User Interface**: Streamlit app for interacting with the system\n",
    "\n",
    "Let's look at each component in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Processing\n",
    "\n",
    "The Document Processor (`document_processor.py`) handles:\n",
    "\n",
    "- Loading different types of documents (PDF, TXT, web pages)\n",
    "- Splitting documents into chunks\n",
    "- Preparing text for embedding\n",
    "\n",
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_processor import DocumentProcessor\n",
    "\n",
    "# Initialize the processor\n",
    "processor = DocumentProcessor()\n",
    "\n",
    "# Example: Process a text file\n",
    "documents = processor.process_file(\"example.txt\")\n",
    "print(f\"Number of chunks: {len(documents)}\")\n",
    "print(f\"First chunk: {documents[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vector Store\n",
    "\n",
    "The Vector Store (`vector_store.py`) manages:\n",
    "\n",
    "- Document embeddings using Ollama\n",
    "- Storage in Qdrant vector database\n",
    "- Similarity search for retrieval\n",
    "\n",
    "Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_store import VectorStore\n",
    "\n",
    "# Initialize the vector store\n",
    "vector_store = VectorStore()\n",
    "\n",
    "# Add documents\n",
    "vector_store.add_documents(documents)\n",
    "\n",
    "# Search for similar documents\n",
    "results = vector_store.similarity_search(\"What is the main topic?\")\n",
    "print(f\"Found {len(results)} relevant documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG System\n",
    "\n",
    "The RAG System (`rag_system.py`) combines:\n",
    "\n",
    "- Document processing\n",
    "- Vector storage and retrieval\n",
    "- Language model generation\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_system import RAGSystem\n",
    "\n",
    "# Initialize the RAG system\n",
    "rag = RAGSystem()\n",
    "\n",
    "# Add documents\n",
    "rag.add_documents([\"example.txt\"])\n",
    "\n",
    "# Ask a question\n",
    "response = rag.query(\"What is the main topic?\")\n",
    "print(f\"Answer: {response['answer']}\")\n",
    "print(f\"Sources: {len(response['sources'])} relevant documents found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. User Interface\n",
    "\n",
    "The Streamlit interface (`app.py`) provides:\n",
    "\n",
    "- Document upload\n",
    "- URL input\n",
    "- Chat interface\n",
    "- Source display\n",
    "\n",
    "To run the interface:\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. How It All Works Together\n",
    "\n",
    "1. User uploads documents or adds URLs\n",
    "2. Documents are processed and split into chunks\n",
    "3. Chunks are embedded and stored in Qdrant\n",
    "4. When user asks a question:\n",
    "   - System retrieves relevant document chunks\n",
    "   - Language model generates answer using retrieved context\n",
    "   - Answer and sources are displayed to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Concepts Explained\n",
    "\n",
    "### Embeddings\n",
    "- Numerical representations of text\n",
    "- Capture semantic meaning\n",
    "- Enable similarity search\n",
    "\n",
    "### Vector Database\n",
    "- Stores document embeddings\n",
    "- Enables fast similarity search\n",
    "- Qdrant is our chosen solution\n",
    "\n",
    "### Language Model\n",
    "- Generates human-like text\n",
    "- Uses retrieved context\n",
    "- We use Ollama with Llama 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices\n",
    "\n",
    "1. **Document Chunking**\n",
    "   - Use appropriate chunk sizes\n",
    "   - Include overlap between chunks\n",
    "   - Maintain context\n",
    "\n",
    "2. **Prompt Engineering**\n",
    "   - Clear instructions\n",
    "   - Context formatting\n",
    "   - Source attribution\n",
    "\n",
    "3. **System Design**\n",
    "   - Modular components\n",
    "   - Clear interfaces\n",
    "   - Error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "1. Try different document types\n",
    "2. Experiment with chunk sizes\n",
    "3. Modify the prompt template\n",
    "4. Add more features to the UI\n",
    "5. Explore different language models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
